{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQqZrFUoM7wGYXj4qPclWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishnuvikasS/True-and-Fake-News-Prediction/blob/main/Fake_news_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "True and Fake News Prediction"
      ],
      "metadata": {
        "id": "I46eK3v5rK9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si0R4KJCrHOs",
        "outputId": "4abf4ef0-1d08-4f7c-bf7a-87e8d5328027"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#importing the required libraries for the Analysis of the project.\n",
        ""
      ],
      "metadata": {
        "id": "3RegvPT3rPuL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test=pd.read_csv('/content/drive/MyDrive/DATASET 2/Fake news Prediction')\n",
        "##import necessary libraries and load dataset"
      ],
      "metadata": {
        "id": "q1dSJSVurRQy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train=pd.read_csv('/content/drive/MyDrive/DATASET 2/train (3).csv ')\n",
        "##import necessary libraries and load dataset\n",
        ""
      ],
      "metadata": {
        "id": "EpDU2aS3rWb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Structure and Content"
      ],
      "metadata": {
        "id": "9uAiSTlwrY-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train.shape\n",
        "# shape function Helps us identify how many rows and columns we have acoording to our data set\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "dDmpaZGlrfZE",
        "outputId": "65e77d60-e3a9-49a2-eb82-943afe5bba30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-907a8865aba8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# shape function Helps us identify how many rows and columns we have acoording to our data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test.shape\n",
        "# shape function Helps us identify how many rows and columns we have acoording to our data set.\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZzVLnBmrgQ7",
        "outputId": "5e558120-5515-475d-88c4-d50d955c2402"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 823)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train.info()\n",
        "#display the information about the datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "9K09e1LYri1U",
        "outputId": "a5ef3081-47ba-4b99-93d8-86c93b94c83b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d91e4ed28486>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#display the information about the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train.isnull().sum()\n",
        "#display number of missing values of each column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "cYSR03l2rkhU",
        "outputId": "170e80f1-f19e-4df9-d983-a3f8c2ea814a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-209e5dca6a12>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#display number of missing values of each column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train.describe()\n",
        "#display descriptive statistics\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "13SyfB6rrmAU",
        "outputId": "fa9254b2-d6f8-47a9-f043-3a9ac1bcd441"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1b9ce232556b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#display descriptive statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "zAHxVzHUrno2",
        "outputId": "3e25dd4e-348a-466b-a899-e5affc3342a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-531822e3e38f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#display first few rows of the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "9VYmUU66rs_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Removing the null values"
      ],
      "metadata": {
        "id": "gruU8FaBrxJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train=Train.fillna(' ')\n",
        "#Replace the missing values in the Train dataset with a space (' ')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "cxRCnPHErvIH",
        "outputId": "b5528b2e-51d1-4f00-c7c1-bf7d9e59c15a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fab775a5bded>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Replace the missing values in the Train dataset with a space (' ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test=Test.fillna(' ')\n",
        "#Replace the missing values in the Test dataset with a space (' ')\n",
        ""
      ],
      "metadata": {
        "id": "DXeP0VWbr3A4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.isnull().sum()\n",
        "#display number of missing values of each column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "JCbIxtPpr3hv",
        "outputId": "b36de014-f85f-4bdc-c5dd-e6a2e91516f9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-209e5dca6a12>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#display number of missing values of each column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test.info()\n",
        "#display information about the datasets\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PYFWxZfr5TY",
        "outputId": "47c3ff71-4443-467b-c673-3261c6d6bb27"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 0 entries\n",
            "Columns: 823 entries, {\"nbformat\":4 to metadata:{\"id\":\"eAlSWXw2vL0M\"}}]}\n",
            "dtypes: object(823)\n",
            "memory usage: 124.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test.isnull().sum()\n",
        "#display number of missing values of each column\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "my3AoICEr8tB",
        "outputId": "c78299f0-6f08-4cf2-e6f5-281ab47b730a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"nbformat\":4                                                                                            0\n",
              "nbformat_minor:0                                                                                         0\n",
              "metadata:{\"colab\":{\"provenance\":[]                                                                       0\n",
              "toc_visible:true                                                                                         0\n",
              "authorship_tag:\"ABX9TyPjbn0x427ySBWj2D6ARKFT\"}                                                           0\n",
              "                                                                                                        ..\n",
              "6.Stemming or Lemmatization: Reducing words to their root forms for consistency.\\n                       0\n",
              "7.Vectorization: Converting text into numerical data for model input.\\n                                  0\n",
              "\\n.9                                                                                                     0\n",
              "These preprocessing steps enhance data quality, enabling accurate true and fake news classification.]    0\n",
              "metadata:{\"id\":\"eAlSWXw2vL0M\"}}]}                                                                        0\n",
              "Length: 823, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>{\"nbformat\":4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nbformat_minor:0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metadata:{\"colab\":{\"provenance\":[]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toc_visible:true</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>authorship_tag:\"ABX9TyPjbn0x427ySBWj2D6ARKFT\"}</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.Stemming or Lemmatization: Reducing words to their root forms for consistency.\\n</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.Vectorization: Converting text into numerical data for model input.\\n</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\\n.9</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>These preprocessing steps enhance data quality, enabling accurate true and fake news classification.]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metadata:{\"id\":\"eAlSWXw2vL0M\"}}]}</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>823 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test.describe()\n",
        "#display descriptive statistics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "t3NjyQw6r_I7",
        "outputId": "89414a0a-2280-4367-912d-0a8b6ed87b9a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       {\"nbformat\":4 nbformat_minor:0 metadata:{\"colab\":{\"provenance\":[]  \\\n",
              "count              0                0                                  0   \n",
              "unique             0                0                                  0   \n",
              "top              NaN              NaN                                NaN   \n",
              "freq             NaN              NaN                                NaN   \n",
              "\n",
              "       toc_visible:true authorship_tag:\"ABX9TyPjbn0x427ySBWj2D6ARKFT\"}  \\\n",
              "count                 0                                              0   \n",
              "unique                0                                              0   \n",
              "top                 NaN                                            NaN   \n",
              "freq                NaN                                            NaN   \n",
              "\n",
              "       kernelspec:{\"name\":\"python3\" display_name:\"Python 3\"}  \\\n",
              "count                             0                        0   \n",
              "unique                            0                        0   \n",
              "top                             NaN                      NaN   \n",
              "freq                            NaN                      NaN   \n",
              "\n",
              "       language_info:{\"name\":\"python\"}} cells:[{\"cell_type\":\"markdown\"  \\\n",
              "count                                 0                              0   \n",
              "unique                                0                              0   \n",
              "top                                 NaN                            NaN   \n",
              "freq                                NaN                            NaN   \n",
              "\n",
              "       source:[\"True and Fake News Prediction\"]  ...  \\\n",
              "count                                         0  ...   \n",
              "unique                                        0  ...   \n",
              "top                                         NaN  ...   \n",
              "freq                                        NaN  ...   \n",
              "\n",
              "       1.Removing Null Values: Discarding incomplete or missing data to ensure dataset quality.\\n  \\\n",
              "count                                                   0                                           \n",
              "unique                                                  0                                           \n",
              "top                                                   NaN                                           \n",
              "freq                                                  NaN                                           \n",
              "\n",
              "       2.Tokenization: Splitting text into words or phrases for detailed analysis.\\n  \\\n",
              "count                                                   0                              \n",
              "unique                                                  0                              \n",
              "top                                                   NaN                              \n",
              "freq                                                  NaN                              \n",
              "\n",
              "       3.Lower Casing Text: Standardizing text by converting all characters to lowercase.\\n  \\\n",
              "count                                                   0                                     \n",
              "unique                                                  0                                     \n",
              "top                                                   NaN                                     \n",
              "freq                                                  NaN                                     \n",
              "\n",
              "       4.Removal of Punctuation: Simplifying text by stripping unnecessary punctuation.\\n  \\\n",
              "count                                                   0                                   \n",
              "unique                                                  0                                   \n",
              "top                                                   NaN                                   \n",
              "freq                                                  NaN                                   \n",
              "\n",
              "       5.Removal of Stop Words: Eliminating common, non-informative words.\\n  \\\n",
              "count                                                   0                      \n",
              "unique                                                  0                      \n",
              "top                                                   NaN                      \n",
              "freq                                                  NaN                      \n",
              "\n",
              "       6.Stemming or Lemmatization: Reducing words to their root forms for consistency.\\n  \\\n",
              "count                                                   0                                   \n",
              "unique                                                  0                                   \n",
              "top                                                   NaN                                   \n",
              "freq                                                  NaN                                   \n",
              "\n",
              "       7.Vectorization: Converting text into numerical data for model input.\\n  \\\n",
              "count                                                   0                        \n",
              "unique                                                  0                        \n",
              "top                                                   NaN                        \n",
              "freq                                                  NaN                        \n",
              "\n",
              "       \\n.9  \\\n",
              "count     0   \n",
              "unique    0   \n",
              "top     NaN   \n",
              "freq    NaN   \n",
              "\n",
              "       These preprocessing steps enhance data quality, enabling accurate true and fake news classification.]  \\\n",
              "count                                                   0                                                      \n",
              "unique                                                  0                                                      \n",
              "top                                                   NaN                                                      \n",
              "freq                                                  NaN                                                      \n",
              "\n",
              "       metadata:{\"id\":\"eAlSWXw2vL0M\"}}]}  \n",
              "count                                  0  \n",
              "unique                                 0  \n",
              "top                                  NaN  \n",
              "freq                                 NaN  \n",
              "\n",
              "[4 rows x 823 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0da2f261-2069-4d9b-8273-f14fce5314ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>{\"nbformat\":4</th>\n",
              "      <th>nbformat_minor:0</th>\n",
              "      <th>metadata:{\"colab\":{\"provenance\":[]</th>\n",
              "      <th>toc_visible:true</th>\n",
              "      <th>authorship_tag:\"ABX9TyPjbn0x427ySBWj2D6ARKFT\"}</th>\n",
              "      <th>kernelspec:{\"name\":\"python3\"</th>\n",
              "      <th>display_name:\"Python 3\"}</th>\n",
              "      <th>language_info:{\"name\":\"python\"}}</th>\n",
              "      <th>cells:[{\"cell_type\":\"markdown\"</th>\n",
              "      <th>source:[\"True and Fake News Prediction\"]</th>\n",
              "      <th>...</th>\n",
              "      <th>1.Removing Null Values: Discarding incomplete or missing data to ensure dataset quality.\\n</th>\n",
              "      <th>2.Tokenization: Splitting text into words or phrases for detailed analysis.\\n</th>\n",
              "      <th>3.Lower Casing Text: Standardizing text by converting all characters to lowercase.\\n</th>\n",
              "      <th>4.Removal of Punctuation: Simplifying text by stripping unnecessary punctuation.\\n</th>\n",
              "      <th>5.Removal of Stop Words: Eliminating common, non-informative words.\\n</th>\n",
              "      <th>6.Stemming or Lemmatization: Reducing words to their root forms for consistency.\\n</th>\n",
              "      <th>7.Vectorization: Converting text into numerical data for model input.\\n</th>\n",
              "      <th>\\n.9</th>\n",
              "      <th>These preprocessing steps enhance data quality, enabling accurate true and fake news classification.]</th>\n",
              "      <th>metadata:{\"id\":\"eAlSWXw2vL0M\"}}]}</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 823 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0da2f261-2069-4d9b-8273-f14fce5314ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0da2f261-2069-4d9b-8273-f14fce5314ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0da2f261-2069-4d9b-8273-f14fce5314ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e2edb23-9d9a-4bd5-99b3-c0ef1af36479\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e2edb23-9d9a-4bd5-99b3-c0ef1af36479')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e2edb23-9d9a-4bd5-99b3-c0ef1af36479 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "09HEkw4NsBhD",
        "outputId": "a27e1922-5d12-47bc-e105-0aa92bb923df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [{\"nbformat\":4, nbformat_minor:0, metadata:{\"colab\":{\"provenance\":[], toc_visible:true, authorship_tag:\"ABX9TyPjbn0x427ySBWj2D6ARKFT\"}, kernelspec:{\"name\":\"python3\", display_name:\"Python 3\"}, language_info:{\"name\":\"python\"}}, cells:[{\"cell_type\":\"markdown\", source:[\"True and Fake News Prediction\"], metadata:{\"id\":\"I46eK3v5rK9I\"}}, {\"cell_type\":\"code\", source:[\"from google.colab import drive\\n\", drive.mount('/content/drive')], metadata:{\"colab\":{\"base_uri\":\"https://localhost:8080/\"}, id:\"Si0R4KJCrHOs\", executionInfo:{\"status\":\"ok\", timestamp:1724693544560, user_tz:-330, elapsed:26424, user:{\"displayName\":\"VISHNU VIKAS\", userId:\"03254113786979667873\"}}, outputId:\"4abf4ef0-1d08-4f7c-bf7a-87e8d5328027\"}, execution_count:1, outputs:[{\"output_type\":\"stream\", name:\"stdout\", text:[\"Mounted at /content/drive\\n\"]}]}, {\"cell_type\":\"code\".1, source:[\"import numpy as np\\n\", import pandas as pd\\n, #importing the required libraries for the Analysis of the project.\\n, ], metadata:{\"id\":\"3RegvPT3rPuL\", executionInfo:{\"status\":\"ok\".1, timestamp:1724693544561, user_tz:-330.1, elapsed:14, user:{\"displayName\":\"VISHNU VIKAS\".1, userId:\"03254113786979667873\"}}}, execution_count:2, outputs:[]}, {\"cell_type\":\"code\".2, source:[\"Test=pd.read_csv('/')\\n\", ##import necessary libraries and load dataset], metadata:{\"colab\":{\"base_uri\":\"https://localhost:8080/\", height:321}, id:\"q1dSJSVurRQy\", executionInfo:{\"status\":\"error\", timestamp:1724693544562, user_tz:-330.2, elapsed:13, user:{\"displayName\":\"VISHNU VIKAS\".2, userId:\"03254113786979667873\"}}.1, outputId:\"8310a4f2-0551-4b2c-f57f-df664d05c0d3\"}, execution_count:3, outputs:[{\"output_type\":\"error\", ename:\"FileNotFoundError\", evalue:\"[Errno 2] No such file or directory: '/content/drive/MyDrive/True and Fake News Prediction /test.csv'\", traceback:[\"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\", \\u001b[0;31mFileNotFoundError\\u001b[0m                         Traceback (most recent call last), \\u001b[0;32m<ipython-input-3-00a242fbec36>\\u001b[0m in \\u001b[0;36m<cell line: 1>\\u001b[0;34m()\\u001b[0m\\n\\u001b[0;32m----> 1\\u001b[0;31m \\u001b[0mTest\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mpd\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mread_csv\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m'/content/drive/MyDrive/True and Fake News Prediction /test.csv'\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m      2\\u001b[0m \\u001b[0;31m##import necessary libraries and load dataset\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n, \\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\\u001b[0m in \\u001b[0;36mread_csv\\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\\u001b[0m\\n\\u001b[1;32m    946\\u001b[0m     \\u001b[0mkwds\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mupdate\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkwds_defaults\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    947\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 948\\u001b[0;31m     \\u001b[0;32mreturn\\u001b[0m \\u001b[0m_read\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mfilepath_or_buffer\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mkwds\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    949\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    950\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n, \\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\\u001b[0m in \\u001b[0;36m_read\\u001b[0;34m(filepath_or_buffer, kwds)\\u001b[0m\\n\\u001b[1;32m    609\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    610\\u001b[0m     \\u001b[0;31m# Create the parser.\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 611\\u001b[0;31m     \\u001b[0mparser\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mTextFileReader\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mfilepath_or_buffer\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwds\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    612\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    613\\u001b[0m     \\u001b[0;32mif\\u001b[0m \\u001b[0mchunksize\\u001b[0m \\u001b[0;32mor\\u001b[0m \\u001b[0miterator\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n, \\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, f, engine, **kwds)\\u001b[0m\\n\\u001b[1;32m   1446\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1447\\u001b[0m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mhandles\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0mIOHandles\\u001b[0m \\u001b[0;34m|\\u001b[0m \\u001b[0;32mNone\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1448\\u001b[0;31m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_engine\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_make_engine\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mf\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mengine\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1449\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1450\\u001b[0m     \\u001b[0;32mdef\\u001b[0m \\u001b[0mclose\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m)\\u001b[0m \\u001b[0;34m->\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n, \\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\\u001b[0m in \\u001b[0;36m_make_engine\\u001b[0;34m(self, f, engine)\\u001b[0m\\n\\u001b[1;32m   1703\\u001b[0m                 \\u001b[0;32mif\\u001b[0m \\u001b[0;34m\\b\\\"\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0;32min\\u001b[0m \\u001b[0mmode\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1704\\u001b[0m                     \\u001b[0mmode\\u001b[0m \\u001b[0;34m+=\\u001b[0m \\u001b[0;34m\\\"b\\\"\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1705\\u001b[0;31m             self.handles = get_handle(\\n\\u001b[0m\\u001b[1;32m   1706\\u001b[0m                 \\u001b[0mf\\u001b[0m\\u001b[0;34m, \\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1707\\u001b[0m                 \\u001b[0mmode\\u001b[0m\\u001b[0;34m, \\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\", \\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\\u001b[0m in \\u001b[0;36mget_handle\\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\\u001b[0m\\n\\u001b[1;32m    861\\u001b[0m         \\u001b[0;32mif\\u001b[0m \\u001b[0mioargs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mencoding\\u001b[0m \\u001b[0;32mand\\u001b[0m \\u001b[0;34m\\b\\\"\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0;32min\\u001b[0m \\u001b[0mioargs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmode\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    862\\u001b[0m             \\u001b[0;31m# Encoding\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 863\\u001b[0;31m             handle = open(\\n\\u001b[0m\\u001b[1;32m    864\\u001b[0m                 \\u001b[0mhandle\\u001b[0m\\u001b[0;34m, \\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    865\\u001b[0m                 \\u001b[0mioargs\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmode\\u001b[0m\\u001b[0;34m, \\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\".1, \\u001b[0;31mFileNotFoundError\\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/True and Fake News Prediction /test.csv']}]}, {\"cell_type\":\"code\".3, source:[\"Train=pd.read_csv('/content/drive/MyDrive/True and Fake News Prediction /train.csv')\\n\", ##import necessary libraries and load dataset\\n, ].1, metadata:{\"id\":\"EpDU2aS3rWb6\", executionInfo:{\"status\":\"aborted\", timestamp:1724693545294, user_tz:-330.3, elapsed:741, user:{\"displayName\":\"VISHNU VIKAS\".3, userId:\"03254113786979667873\"}}}.1, execution_count:null, outputs:[]}.1, {\"cell_type\":\"markdown\", source:[\"# Data Structure and Content\"], metadata:{\"id\":\"9uAiSTlwrY-S\"}}, {\"cell_type\":\"code\".4, source:[\"Train.shape\\n\", # shape function Helps us identify how many rows and columns we have acoording to our data set\\n, ].2, metadata:{\"id\":\"dDmpaZGlrfZE\", executionInfo:{\"status\":\"aborted\".1, timestamp:1724693545295, user_tz:-330.4, elapsed:26, user:{\"displayName\":\"VISHNU VIKAS\".4, userId:\"03254113786979667873\"}}}.2, execution_count:null.1, outputs:[]}.2, ...]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 823 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b953f21a-6744-4771-bcec-93c991f26d40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>{\"nbformat\":4</th>\n",
              "      <th>nbformat_minor:0</th>\n",
              "      <th>metadata:{\"colab\":{\"provenance\":[]</th>\n",
              "      <th>toc_visible:true</th>\n",
              "      <th>authorship_tag:\"ABX9TyPjbn0x427ySBWj2D6ARKFT\"}</th>\n",
              "      <th>kernelspec:{\"name\":\"python3\"</th>\n",
              "      <th>display_name:\"Python 3\"}</th>\n",
              "      <th>language_info:{\"name\":\"python\"}}</th>\n",
              "      <th>cells:[{\"cell_type\":\"markdown\"</th>\n",
              "      <th>source:[\"True and Fake News Prediction\"]</th>\n",
              "      <th>...</th>\n",
              "      <th>1.Removing Null Values: Discarding incomplete or missing data to ensure dataset quality.\\n</th>\n",
              "      <th>2.Tokenization: Splitting text into words or phrases for detailed analysis.\\n</th>\n",
              "      <th>3.Lower Casing Text: Standardizing text by converting all characters to lowercase.\\n</th>\n",
              "      <th>4.Removal of Punctuation: Simplifying text by stripping unnecessary punctuation.\\n</th>\n",
              "      <th>5.Removal of Stop Words: Eliminating common, non-informative words.\\n</th>\n",
              "      <th>6.Stemming or Lemmatization: Reducing words to their root forms for consistency.\\n</th>\n",
              "      <th>7.Vectorization: Converting text into numerical data for model input.\\n</th>\n",
              "      <th>\\n.9</th>\n",
              "      <th>These preprocessing steps enhance data quality, enabling accurate true and fake news classification.]</th>\n",
              "      <th>metadata:{\"id\":\"eAlSWXw2vL0M\"}}]}</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 823 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b953f21a-6744-4771-bcec-93c991f26d40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b953f21a-6744-4771-bcec-93c991f26d40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b953f21a-6744-4771-bcec-93c991f26d40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train['subject']=Train['author'] + ' ' + Train['title']\n",
        "# Create a new column 'subject' by concatenating the 'author' and 'title' columns with a space in between\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "AQcbeDwjsFOC",
        "outputId": "7e837e34-d51a-44bf-ac41-2ba5e62b2ffe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8ab6e51001aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create a new column 'subject' by concatenating the 'author' and 'title' columns with a space in between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "vDACGDVisIlk",
        "outputId": "611a357a-b382-4b1b-cc3b-84bf2dacc075"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-da7e143f04ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#display first few rows of the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "id": "4g8kyjcLsJX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "XE8sjRSosbDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# Download the Punkt tokenizer models for tokenization\n",
        ""
      ],
      "metadata": {
        "id": "xL09_Pf8sc94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "Train['tokens']=Train['subject'].apply(word_tokenize)\n",
        "# Tokenize the 'subject' column and create a new column 'tokens'"
      ],
      "metadata": {
        "id": "uFCu_NROseyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "id": "Ow5d8UaMshKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Lowercasing the text"
      ],
      "metadata": {
        "id": "jDQ4VZ7Fsngj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train['subject']=Train['subject'].str.lower()\n",
        "# Convert all text in the 'subject' column to lowercase"
      ],
      "metadata": {
        "id": "VfP_McYJsi6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets\n",
        ""
      ],
      "metadata": {
        "id": "HXkzyHkCstsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Removal of punctuation"
      ],
      "metadata": {
        "id": "OPxNCSxJsv9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train['subject']=Train['subject'].str.replace('[^\\w\\s]',' ')\n",
        "# Remove all punctuation marks from the 'subject' column"
      ],
      "metadata": {
        "id": "O_LFtMBnsuW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "id": "aIbDMh1TsyQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Removal of stop words"
      ],
      "metadata": {
        "id": "32G1aKJbs1k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "# Download the stopwords corpus for removing stop words"
      ],
      "metadata": {
        "id": "pfWhGWhks2Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw=set(nltk.corpus.stopwords.words('english'))\n",
        "print(sw)\n",
        "# Create a set of English stopwords and print it"
      ],
      "metadata": {
        "id": "KMbSDddJs4fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train['subject'] = Train['subject'].apply(lambda x: ' '.join([word for word in x.split() if word not in sw]))\n",
        "# Here we try to remove the stopwords by adding only the words which are not in the SW stopword set."
      ],
      "metadata": {
        "id": "BJodMl3ls6ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "id": "JogJFiuWs8yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.stemming or lammatization"
      ],
      "metadata": {
        "id": "jLvefJJ7tAGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "# Import the PorterStemmer class for stemming"
      ],
      "metadata": {
        "id": "zS-JbpKTs-Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Stemmer=PorterStemmer()\n",
        "#To Apply Stemming or Lemmatization :        stemmer = PorterStemmer()\n",
        "Train['subject'] = Train['subject'].apply(lambda x: ' '.join([Stemmer.stem(word) for word in x.split()]))\n",
        "# Stemming is the simple process of reducing the words to their root forms\n",
        ""
      ],
      "metadata": {
        "id": "qRS6A3CetPJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "id": "frm2nwv9tRN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorisation"
      ],
      "metadata": {
        "id": "hMNVEksOtXuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=Train['subject']\n",
        "y=Train['label']\n",
        "# Assign the 'subject' column to variable x (features) and the 'label' column to variable y (target)"
      ],
      "metadata": {
        "id": "D36v1AsKtqkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Import the TfidfVectorizer class for vectorizing text data"
      ],
      "metadata": {
        "id": "vk1qhwLzts3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vt=TfidfVectorizer()\n",
        "Vt.fit(x)\n",
        "# Fit the TfidfVectorizer on the 'subject' column of the Train dataset"
      ],
      "metadata": {
        "id": "uM_hK5krtvMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "7JF9-XDpt0wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.head()\n",
        "#display first few rows of the datasets"
      ],
      "metadata": {
        "id": "WOmuS3-7t3JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=Vt.transform(x)\n",
        "# Transform the 'subject' column of the Train dataset using the fitted TfidfVectorizer"
      ],
      "metadata": {
        "id": "IuWqsAeRt4-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "# Print the transformed data\n",
        ""
      ],
      "metadata": {
        "id": "dHp3iNKut-xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For building the machine learning models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "RQTelCSzuBii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For evaluating the models using the metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "from sklearn.model_selection  import cross_val_score as CVS\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "ulVc3DPTuEWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain,xTest,yTrain,yTest=train_test_split(x,y,test_size=0.2,stratify=y,random_state=42)\n",
        "# Split the data into training and testing sets\n",
        ""
      ],
      "metadata": {
        "id": "_d7afI-_uGO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model=LogisticRegression()\n",
        "# Create a Logistic Regression model\n",
        ""
      ],
      "metadata": {
        "id": "5OPjWgHYuJHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.fit(xTrain,yTrain)\n",
        "# Fit the Logistic Regression model on the training data"
      ],
      "metadata": {
        "id": "rMlgmNz6uK8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "N7iCaiG0ujZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrpredict=Model.predict(xTrain)\n",
        "# Make predictions on the training data using the trained Logistic Regression model\n",
        ""
      ],
      "metadata": {
        "id": "068EXEejuO6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=accuracy_score(yTrain,ytrpredict)\n",
        "precision=precision_score(yTrain,ytrpredict)\n",
        "recall=recall_score(yTrain,ytrpredict)\n",
        "f1=f1_score(yTrain,ytrpredict)\n",
        "\n",
        "print('Training Accuracy:',accuracy)\n",
        "print('Training Precision:',precision)\n",
        "print('Training Recall:',recall)\n",
        "print('Training F1 Score:',f1)"
      ],
      "metadata": {
        "id": "jJRQSBL5umf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy =accuracy_score(yTrain,ytrpredict)\n",
        "precision = precision_score(yTrain, ytrpredict)\n",
        "recall = recall_score(yTrain, ytrpredict)\n",
        "f1 = f1_score(yTrain, ytrpredict)\n",
        "\n",
        "print(' Training Accuracy:', accuracy)\n",
        "print(' Training Precision:', precision)\n",
        "print(' Training Recall:', recall)\n",
        "print('Training F1 Score:',f1)"
      ],
      "metadata": {
        "id": "b9QDCEr7uopy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Yttpredict=Model.predict(xTest)\n",
        "# Make predictions on the testing data using the trained Logistic Regression model\n",
        ""
      ],
      "metadata": {
        "id": "OgbzEg20utQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy =accuracy_score(yTest,Yttpredict)\n",
        "precision = precision_score(yTest, Yttpredict)\n",
        "recall = recall_score(yTest, Yttpredict)\n",
        "f1 = f1_score(yTest, Yttpredict)\n",
        "\n",
        "print(' Testing Accuracy:', accuracy)\n",
        "print(' Testing Precision:', precision)\n",
        "print(' Testing Recall:', recall)\n",
        "print('Testing F1 Score:',f1)"
      ],
      "metadata": {
        "id": "GF9uT4CouvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "# Import necessary libraries for confusion matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "PfcG-E1euysz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(yTrain,ytrpredict)\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CLUomiCxuzXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(yTest,Yttpredict)\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4PCMbncWu1uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Model"
      ],
      "metadata": {
        "id": "5h_SC-HYu8OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Import the pickle module for serializing and deserializing Python object\n",
        ""
      ],
      "metadata": {
        "id": "_wqf_GakvGbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUMMARY:"
      ],
      "metadata": {
        "id": "gSj55y6ivLH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on predicting the reliability of news articles by analyzing text features such as word patterns and sentiment using Natural Language Processing NLP. The programs data structure efficiently organizes news articles, storing features like text, labels true/fake, and vectorized content, enabling precise content analysis.\n",
        "\n",
        "Data preprocessing is a critical phase in this project, involving several steps to prepare the raw data for machine learning. These steps include:\n",
        "\n",
        "1.Removing Null Values: Discarding incomplete or missing data to ensure dataset quality.\n",
        "2.Tokenization: Splitting text into words or phrases for detailed analysis.\n",
        "3.Lower Casing Text: Standardizing text by converting all characters to lowercase.\n",
        "4.Removal of Punctuation: Simplifying text by stripping unnecessary punctuation.\n",
        "5.Removal of Stop Words: Eliminating common, non-informative words.\n",
        "6.Stemming or Lemmatization: Reducing words to their root forms for consistency.\n",
        "7.Vectorization: Converting text into numerical data for model input.\n",
        "\n",
        "These preprocessing steps enhance data quality, enabling accurate true and fake news classification."
      ],
      "metadata": {
        "id": "eAlSWXw2vL0M"
      }
    }
  ]
}